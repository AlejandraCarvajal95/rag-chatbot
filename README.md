# ğŸ§  RAG Chatbot con LlamaIndex + Together.ai

Este demo muestra cÃ³mo construir un chatbot RAG (Retrieval-Augmented Generation) que indexa documentos empresariales y responde preguntas en lenguaje natural. Utiliza `LlamaIndex` para la recuperaciÃ³n semÃ¡ntica y `Together.ai` como backend LLM (modelo `DeepSeek-V3`). TambiÃ©n incluye una simulaciÃ³n de integraciÃ³n con un CRM externo usando un archivo `clientes.csv`.

---

## ğŸ“ Estructura del proyecto

â”œâ”€â”€ data/
â”‚ â””â”€â”€ data.txt # Documento de referencia indexado
â”œâ”€â”€ clientes.csv # Simula una fuente externa tipo CRM
â”œâ”€â”€ rag_chatbot.py # Chatbot con RAG + integraciÃ³n externa
â”œâ”€â”€ direct_llm_example.py # Consulta directa al modelo LLM sin RAG
â”œâ”€â”€ .env # Contiene TOGETHER_API_KEY
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸš€ TecnologÃ­as utilizadas

- **Python 3.10+**
- **LlamaIndex**
- **Together.ai (modelo: DeepSeek-V3)**
- **Embeddings locales (MiniLM-L6-v2)**
- **Pandas** (para lectura de CSV simulando CRM)
- **dotenv** (manejo de variables de entorno)

---

## ğŸ› ï¸ CÃ³mo ejecutar

1. Clona el repositorio:
```bash
git clone https://github.com/tuusuario/rag-chatbot-demo.git
cd rag-chatbot-demo
```

2. Instala las dependencias:
```bash
pip install -r requirements.txt
```

3. Crea un archivo .env con tu API Key de Together:
```bash
TOGETHER_API_KEY=sk-xxxxxxxxxxxxxxxxx
```

4. Ejecuta el chatbot RAG:
```bash
python rag_chatbot.py
```

5. (Opcional) Ejecuta una consulta directa al modelo (sin RAG):
```bash
python direct_llm_example.py
```
